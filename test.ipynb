{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import class_names\n",
    "from predict import class_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649ms/step\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'putText'\n> Overload resolution failed:\n>  - Can't convert object to 'str' for 'text'\n>  - Can't convert object to 'str' for 'text'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m fcn_8_vgg(n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m27\u001b[39m, input_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m, input_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m320\u001b[39m)\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints/model.weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m segmented_image \u001b[38;5;241m=\u001b[39m predict( \n\u001b[0;32m     21\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[0;32m     22\u001b[0m     inp \u001b[38;5;241m=\u001b[39m image_path,  \u001b[38;5;66;03m# Set to True to overlay the segmentation on the input image\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     show_legends\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Set to True to show legends of class names\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     class_names\u001b[38;5;241m=\u001b[39mclass_names,  \u001b[38;5;66;03m# Replace with actual class names\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     colors\u001b[38;5;241m=\u001b[39mclass_colors  \u001b[38;5;66;03m# Replace with actual class colors\u001b[39;00m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m     29\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(segmented_image)\n",
      "File \u001b[1;32mc:\\Users\\Arjun\\Desktop\\Inter IIT\\predict.py:148\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, inp, out_fname, checkpoints_path, overlay_img, class_names, show_legends, colors, prediction_width, prediction_height, read_image_type)\u001b[0m\n\u001b[0;32m    145\u001b[0m pr \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([x]))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    146\u001b[0m pr \u001b[38;5;241m=\u001b[39m pr\u001b[38;5;241m.\u001b[39mreshape((output_height, output_width, n_classes))\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 148\u001b[0m seg_img \u001b[38;5;241m=\u001b[39m visualize_segmentation(\n\u001b[0;32m    149\u001b[0m     pr, inp, n_classes\u001b[38;5;241m=\u001b[39mn_classes, colors\u001b[38;5;241m=\u001b[39mcolors, overlay_img\u001b[38;5;241m=\u001b[39moverlay_img,\n\u001b[0;32m    150\u001b[0m     show_legends\u001b[38;5;241m=\u001b[39mshow_legends, class_names\u001b[38;5;241m=\u001b[39mclass_names,\n\u001b[0;32m    151\u001b[0m     prediction_width\u001b[38;5;241m=\u001b[39mprediction_width, prediction_height\u001b[38;5;241m=\u001b[39mprediction_height\n\u001b[0;32m    152\u001b[0m )\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_fname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(out_fname, seg_img)\n",
      "File \u001b[1;32mc:\\Users\\Arjun\\Desktop\\Inter IIT\\predict.py:117\u001b[0m, in \u001b[0;36mvisualize_segmentation\u001b[1;34m(seg_arr, inp_img, n_classes, colors, class_names, overlay_img, show_legends, prediction_width, prediction_height)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_legends:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m class_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass names must be provided to show legends.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 117\u001b[0m     legend_img \u001b[38;5;241m=\u001b[39m get_legends(class_names, colors\u001b[38;5;241m=\u001b[39mcolors)\n\u001b[0;32m    118\u001b[0m     seg_img \u001b[38;5;241m=\u001b[39m concat_legends(seg_img, legend_img)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seg_img\n",
      "File \u001b[1;32mc:\\Users\\Arjun\\Desktop\\Inter IIT\\predict.py:73\u001b[0m, in \u001b[0;36mget_legends\u001b[1;34m(class_names, colors)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (class_name, color) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(class_names[:n_classes], colors[:n_classes])):\n\u001b[0;32m     72\u001b[0m     color \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m color]\n\u001b[1;32m---> 73\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(legend, class_name, (\u001b[38;5;241m5\u001b[39m, (i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m17\u001b[39m),\n\u001b[0;32m     74\u001b[0m                 cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_COMPLEX, \u001b[38;5;241m0.5\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(legend, (\u001b[38;5;241m100\u001b[39m, i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m25\u001b[39m), (\u001b[38;5;241m125\u001b[39m, (i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m25\u001b[39m),\n\u001b[0;32m     76\u001b[0m                   \u001b[38;5;28mtuple\u001b[39m(color), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legend\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'putText'\n> Overload resolution failed:\n>  - Can't convert object to 'str' for 'text'\n>  - Can't convert object to 'str' for 'text'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from functions import get_image_array\n",
    "from model import fcn_8_vgg\n",
    "\n",
    "\n",
    "\n",
    "from predict import predict\n",
    "# Function to predict segmentation on a single image\n",
    "# from predict import predict\n",
    "image_path = \"dataset/test/frame11630.jpg\"\n",
    "output_path = \"output.jpg\"\n",
    "\n",
    "# Load the model (ensure the weights are already loaded in your model)\n",
    "model = fcn_8_vgg(n_classes=27, input_height=224, input_width=320)\n",
    "model.load_weights('checkpoints/model.weights.h5')\n",
    "\n",
    "    \n",
    "segmented_image = predict( \n",
    "    model=model, \n",
    "    inp = image_path,  # Set to True to overlay the segmentation on the input image\n",
    "    show_legends=True,  # Set to True to show legends of class names\n",
    "    class_names=class_names,  # Replace with actual class names\n",
    "    colors=class_colors  # Replace with actual class colors\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(segmented_image)\n",
    "plt.axis('off')  # Turn off axis numbers and ticks\n",
    "plt.title('Segmented Image')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
